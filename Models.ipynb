{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1036e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('law_data.csv')\n",
    "\n",
    "#Preprocessing\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df = df[df['region_first'] != 'PO']\n",
    "\n",
    "#One-Hot encode race\n",
    "race_coded = pd.get_dummies(df['race'])\n",
    "df = pd.concat([df, race_coded],axis=1)\n",
    "\n",
    "#One-Hot encode gender\n",
    "gender_coded = pd.get_dummies(df['sex'])\n",
    "gender_coded.columns = ['female', 'male']\n",
    "df = pd.concat([df, gender_coded],axis=1)\n",
    "\n",
    "df = df.drop(columns = ['race', 'sex'])\n",
    "sense_cols = ['Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican', 'Other','Puertorican', 'White', 'female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8260384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#In our model, ZFYA is something we are interested in, so mark it as y, note that the ZFYA is standardized.\n",
    "\n",
    "X = df.loc[:, df.columns !='ZFYA']\n",
    "y = df['ZFYA']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "ne = len(X_test)\n",
    "K = len(sense_cols)  #latent variable knowledge that affects gpa, last and fya, but is not related to race and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f127243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['LSAT'] = X_train['LSAT'].astype(int)\n",
    "X_test['LSAT'] = X_test['LSAT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f8477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_stan_data = {\n",
    "    'N' : n, #number of observations\n",
    "    'K' : K, #number of attributes\n",
    "    'a' : np.array(X_train[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_train['UGPA']), \n",
    "    'lsat' : np.array(X_train['LSAT']),\n",
    "    'zfya' : np.array(y_train)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34ca58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part defines a model for STAN package to use, the model basically defines all distribution in paper page 8.\n",
    "#\n",
    "\n",
    "model= \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  real           zfya[N]; // ZFYA\n",
    "  \n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  \n",
    " vector[K] zero_K;\n",
    " vector[K] one_K;\n",
    " \n",
    " zero_K = rep_vector(0,K);\n",
    " one_K = rep_vector(1,K);\n",
    "\n",
    "}\n",
    "\n",
    "parameters {\n",
    "\n",
    "  vector[N] u;\n",
    "\n",
    "  real ugpa0;\n",
    "  real eta_u_ugpa;\n",
    "  real lsat0;\n",
    "  real eta_u_lsat;\n",
    "  real eta_u_zfya;\n",
    "  \n",
    "  vector[K] eta_a_ugpa;\n",
    "  vector[K] eta_a_lsat;\n",
    "  vector[K] eta_a_zfya;\n",
    "  \n",
    "  \n",
    "  real<lower=0> sigma_g_Sq;\n",
    "}\n",
    "\n",
    "transformed parameters  {\n",
    " // Population standard deviation (a positive real number)\n",
    " real<lower=0> sigma_g;\n",
    " // Standard deviation (derived from variance)\n",
    " sigma_g = sqrt(sigma_g_Sq);\n",
    "}\n",
    "\n",
    "model {\n",
    "  \n",
    "  // don't have data about this\n",
    "  u ~ normal(0, 1);\n",
    "  \n",
    "  ugpa0 ~ normal(0, 1);\n",
    "  eta_u_ugpa ~ normal(0, 1);\n",
    "  lsat0 ~ normal(0, 1);\n",
    "  eta_u_lsat ~ normal(0, 1);\n",
    "  eta_u_zfya ~ normal(0, 1);\n",
    "\n",
    "  eta_a_ugpa ~ normal(zero_K, one_K);\n",
    "  eta_a_lsat ~ normal(zero_K, one_K);\n",
    "  eta_a_zfya ~ normal(zero_K, one_K);\n",
    "\n",
    "  sigma_g_Sq ~ inv_gamma(1, 1);\n",
    "\n",
    "  // have data about these\n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g);\n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat));\n",
    "  zfya ~ normal(eta_u_zfya * u + a * eta_a_zfya, 1);\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e85327",
   "metadata": {},
   "source": [
    "u -> K\n",
    "a -> Include all sensitive variables sex and race using real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6da009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter eta_a_zfya has no priors.\n",
      "Warning: The parameter eta_a_ugpa has no priors.\n",
      "Warning: The parameter eta_a_lsat has no priors.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.008761 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 87.61 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "#Using STAN package with the model we defined above, this would gives us the posterior distribution knowledge\n",
    "#We then use the u we learned to generate samples\n",
    "posterior = stan.build(model, data=law_stan_data, random_seed=1)\n",
    "fit = posterior.sample(num_chains= 1, num_samples= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaec74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_train = fit['u'].mean(axis = 1)\n",
    "pd.DataFrame(U_train).to_csv('U_train.csv')\n",
    "\n",
    "#we trying to get an average of those samples, those are learned using u in trainnig and that would be parameters for test set.\n",
    "\n",
    "ugpa0 = fit['ugpa0'].mean()\n",
    "eta_u_ugpa = fit['eta_u_ugpa'].mean()\n",
    "eta_a_ugpa = fit['eta_a_ugpa'].mean(axis = 1)\n",
    "\n",
    "lsat0 = fit['lsat0'].mean()\n",
    "eta_u_lsat = fit['eta_u_lsat'].mean()\n",
    "eta_a_lsat = fit['eta_a_lsat'].mean(axis = 1)\n",
    "\n",
    "sigma_g = fit['sigma_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25216a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have similar setting for test, in this part, we have datas learned during training. \n",
    "\n",
    "model_u = \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  \n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  //real           zfya[N]; // ZFYA\n",
    "  //int<lower = 0> pass[N]; // PASS\n",
    "  real           ugpa0;\n",
    "  real           eta_u_ugpa;\n",
    "  vector[K]      eta_a_ugpa;\n",
    "  real           lsat0;\n",
    "  real           eta_u_lsat;\n",
    "  vector[K]      eta_a_lsat;\n",
    "  //real           eta_u_zfya;\n",
    "  //vector[K]      eta_a_zfya;\n",
    "  //real           pass0;\n",
    "  //real           eta_u_pass;\n",
    "  //vector[K]      eta_a_pass;\n",
    "  real           sigma_g;\n",
    "  \n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "\n",
    "  vector[N] u;\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  \n",
    "  u ~ normal(0, 1);\n",
    "\n",
    "  // have data about these\n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g); \n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat)); \n",
    "  //zfya ~ normal(eta_u_zfya * u + a * eta_a_zfya,1);\n",
    "  //pass ~ bernoulli_logit(pass0 + eta_u_pass * u + a * eta_a_pass);\n",
    "  \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f71899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Those are data we learned from training\n",
    "\n",
    "law_stan_test_data = {\n",
    "    'N' : ne,#number of test data\n",
    "    'K' : K,#number of protected attributesv\n",
    "    'a' : np.array(X_test[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_test['UGPA']), \n",
    "    'lsat' : np.array(X_test['LSAT']),\n",
    "    #those are learned from training\n",
    "    'ugpa0' : ugpa0,\n",
    "    'eta_u_ugpa' : eta_u_ugpa,\n",
    "    'eta_a_ugpa' : eta_a_ugpa,\n",
    "    'lsat0' : lsat0, \n",
    "    'eta_u_lsat' : eta_u_lsat,\n",
    "    'eta_a_lsat' : eta_a_lsat,\n",
    "    'sigma_g' : sigma_g    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7229eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.001374 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 13.74 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "posterior_test = stan.build(model_u, data=law_stan_test_data, random_seed=1)\n",
    "fit_test = posterior_test.sample(num_chains= 1, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0777fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This would be the knowledge we learned from testing by taking average of all samples\n",
    "\n",
    "U_test = fit_test['u'].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e99bb6",
   "metadata": {},
   "source": [
    "# Fair Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0026a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fair + non-deterministic model (deterministic)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_fair = U_train.reshape(-1,1)\n",
    "X_fair_test = U_test.reshape(-1, 1)\n",
    "\n",
    "lr_fair = LinearRegression()\n",
    "lr_fair.fit(X_fair, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7175eb",
   "metadata": {},
   "source": [
    "# Unfair models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e36c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A. Full model\n",
    "full_list = ['LSAT', 'UGPA', 'Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican','Other', 'Puertorican', 'White', 'female', 'male']\n",
    "lr_full = LinearRegression()\n",
    "lr_full.fit(X_train[full_list], y_train)\n",
    "\n",
    "#B. Unaware model\n",
    "unaware = ['LSAT', 'UGPA']\n",
    "lr_unaware = LinearRegression()\n",
    "lr_unaware.fit(X_train[unaware], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77d1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile to one dataset\n",
    "X_train['ZFYA'] = y_train\n",
    "X_train['Knowledge'] = U_train\n",
    "\n",
    "X_train['Init_class'] = np.sign(X_train['ZFYA'])\n",
    "\n",
    "#fair model\n",
    "X_train['Fair_pred'] = lr_fair.predict(X_fair)\n",
    "X_train['Fair_pred_class'] = np.sign(X_train['Fair_pred'])\n",
    "\n",
    "#full model\n",
    "X_train['full_pred'] = lr_full.predict(X_train[full_list])\n",
    "X_train['full_pred_class'] = np.sign(X_train['full_pred'])\n",
    "\n",
    "#unaware model\n",
    "X_train['unaware_pred'] = lr_unaware.predict(X_train[unaware])\n",
    "X_train['unaware_pred_class'] = np.sign(X_train['unaware_pred'])\n",
    "\n",
    "X_train.to_csv('Full_Training_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80d4901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['ZFYA'] = y_test\n",
    "X_test['Knowledge'] = U_test\n",
    "\n",
    "X_test['Init_class'] = np.sign(X_test['ZFYA'])\n",
    "\n",
    "X_test['Fair_pred'] = lr_fair.predict(X_fair_test)\n",
    "X_test['Fair_pred_class'] = np.sign(X_test['Fair_pred'])\n",
    "\n",
    "X_test['full_pred'] = lr_full.predict(X_test[full_list])\n",
    "X_test['full_pred_class'] = np.sign(X_test['full_pred'])\n",
    "\n",
    "X_test['unaware_pred'] = lr_unaware.predict(X_test[unaware])\n",
    "X_test['unaware_pred_class'] = np.sign(X_test['unaware_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25c6872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('Full_Test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa434575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LSAT', 'UGPA', 'region_first', 'sander_index', 'first_pf',\n",
       "       'Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican', 'Other',\n",
       "       'Puertorican', 'White', 'female', 'male', 'ZFYA', 'Knowledge',\n",
       "       'Init_class', 'Fair_pred', 'Fair_pred_class', 'full_pred',\n",
       "       'full_pred_class', 'unaware_pred', 'unaware_pred_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e071d",
   "metadata": {},
   "source": [
    "# Counterfactual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "371f2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender counterfactual\n",
    "male_counter = X_test['female']\n",
    "female_counter = X_test['male']\n",
    "\n",
    "test_counter = X_test.copy()\n",
    "test_counter['male'] = male_counter\n",
    "test_counter['female'] = female_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7f21162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get everything and male\n",
    "test_counter = test_counter.loc[:, 'LSAT':'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f169a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.00178 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 17.8 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "law_stan_counter_data = {\n",
    "    'N' : ne,\n",
    "    'K' : K,\n",
    "    'a' : np.array(test_counter[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(test_counter['UGPA']), \n",
    "    'lsat' : np.array(test_counter['LSAT']),\n",
    "    'ugpa0' : ugpa0,\n",
    "    'eta_u_ugpa' : eta_u_ugpa,\n",
    "    'eta_a_ugpa' : eta_a_ugpa,\n",
    "    'lsat0' : lsat0, \n",
    "    'eta_u_lsat' : eta_u_lsat,\n",
    "    'eta_a_lsat' : eta_a_lsat,\n",
    "    'sigma_g' : sigma_g    \n",
    "}\n",
    "\n",
    "counter_post = stan.build(model_u, data=law_stan_counter_data, random_seed=1)\n",
    "counter_fit = counter_post.sample(num_chains= 1, num_samples=50)\n",
    "counter_U = counter_fit['u'].mean(axis = 1)\n",
    "counter_fair_K = counter_U.reshape(-1, 1)\n",
    "\n",
    "counter_fair = LinearRegression()\n",
    "counter_fair.fit(counter_fair_K, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10777419",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter['ZFYA'] = y_test\n",
    "test_counter['Knowledge'] = counter_fair_K\n",
    "test_counter['Init_class'] = np.sign(X_test['ZFYA'])\n",
    "\n",
    "\n",
    "#knowledge is not affected by gender, direct prediction\n",
    "test_counter['Fair_pred'] = counter_fair.predict(counter_fair_K)\n",
    "test_counter['Fair_pred_class'] = np.sign(test_counter['Fair_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d467093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gender counterfactual\n",
    "train_counter = X_train.copy()\n",
    "\n",
    "male_counter = X_train['female']\n",
    "female_counter = X_train['male']\n",
    "\n",
    "train_counter['male'] = male_counter\n",
    "train_counter['female'] = female_counter\n",
    "\n",
    "#Counterfactual LSAT and UGPA - by causal model, affected by gender, need to learn first\n",
    "counter_LSAT = LinearRegression(fit_intercept = True)\n",
    "counter_LSAT.fit(train_counter[sense_cols], train_counter['LSAT'])\n",
    "\n",
    "counter_UGPA = LinearRegression(fit_intercept = True)\n",
    "counter_UGPA.fit(train_counter[sense_cols], train_counter['UGPA'])\n",
    "\n",
    "#counter_ZFYA = LinearRegression(fit_intercept = True)\n",
    "#counter_ZFYA.fit(train_counter[sense_cols], train_counter['ZFYA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc42fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counterfactual LSAT and UGPA\n",
    "test_counter['LSAT'] = counter_LSAT.predict(test_counter[sense_cols])\n",
    "test_counter['UGPA'] = counter_UGPA.predict(test_counter[sense_cols])\n",
    "#y_test_counter = counter_ZFYA.predict(test_counter[sense_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a88ff16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counterfactual full\n",
    "test_counter['full_pred'] = lr_full.predict(test_counter[full_list])\n",
    "test_counter['full_pred_class'] = np.sign(test_counter['full_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counterfactual unaware\n",
    "test_counter['unaware_pred'] = lr_unaware.predict(test_counter[unaware])\n",
    "test_counter['unaware_pred_class'] = np.sign(test_counter['unaware_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c14ba5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter.to_csv('Counter_Test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb3631",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd34186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Full_test_df.csv')\n",
    "df2 = pd.read_csv('Counter_test_df.csv')\n",
    "mapping = {-1: 'unsuccessful', 1: 'successful'}\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Gender': df1['female'].map({0: 'male', 1:'female'}),\n",
    "    'Init_class': df1['Init_class'].map(mapping),\n",
    "    \n",
    "    'Fair_pred_class': df1['Fair_pred_class'].map(mapping),\n",
    "    'Counter_fair_pred_class': df2['Fair_pred_class'].map(mapping),\n",
    "    \n",
    "    'full_pred_class':df1['full_pred_class'].map(mapping),\n",
    "    'Counter_full_pred_class': df2['full_pred_class'].map(mapping),\n",
    "    \n",
    "    'unaware_pred_class':df1['unaware_pred_class'].map(mapping),\n",
    "    'Counter_unaware_pred_class': df2['unaware_pred_class'].map(mapping)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb191e",
   "metadata": {},
   "source": [
    "# Female: Predicted probability to succeed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4de5c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = result[result['Gender'] == 'female']\n",
    "male = result[result['Gender'] == 'male']   \n",
    "n_female = len(female)\n",
    "n_male = len(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a39a9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proability</th>\n",
       "      <th>Counterfactual Probabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Model</th>\n",
       "      <td>0.718220</td>\n",
       "      <td>0.806674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unaware Model</th>\n",
       "      <td>0.661547</td>\n",
       "      <td>0.863347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair Model(learned)</th>\n",
       "      <td>0.736758</td>\n",
       "      <td>0.934322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Proability  Counterfactual Probabilty\n",
       "Full Model             0.718220                   0.806674\n",
       "Unaware Model          0.661547                   0.863347\n",
       "Fair Model(learned)    0.736758                   0.934322"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Proability': [len(female[female['full_pred_class'] == 'successful'])/n_female, \n",
    "                   len(female[female['unaware_pred_class'] == 'successful'])/n_female,\n",
    "                   len(female[female['Fair_pred_class'] == 'successful'])/n_female\n",
    "                  ],\n",
    "    'Counterfactual Probabilty': [len(female[female['Counter_full_pred_class'] == 'successful'])/n_female,\n",
    "                                 len(female[female['Counter_unaware_pred_class'] == 'successful'])/n_female,\n",
    "                                 len(female[female['Counter_fair_pred_class'] == 'successful'])/n_female]\n",
    "}, index = ['Full Model', 'Unaware Model', 'Fair Model(learned)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8f62f",
   "metadata": {},
   "source": [
    "# Male: Predicted probability to succeed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0d5ca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proability</th>\n",
       "      <th>Counterfactual Probabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Model</th>\n",
       "      <td>0.759109</td>\n",
       "      <td>0.862753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unaware Model</th>\n",
       "      <td>0.650607</td>\n",
       "      <td>0.913360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair Model(learned)</th>\n",
       "      <td>0.729960</td>\n",
       "      <td>0.794332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Proability  Counterfactual Probabilty\n",
       "Full Model             0.759109                   0.862753\n",
       "Unaware Model          0.650607                   0.913360\n",
       "Fair Model(learned)    0.729960                   0.794332"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Proability': [len(male[male['full_pred_class'] == 'successful'])/n_male, \n",
    "                   len(male[male['unaware_pred_class'] == 'successful'])/n_male,\n",
    "                   len(male[male['Fair_pred_class'] == 'successful'])/n_male\n",
    "                  ],\n",
    "    'Counterfactual Probabilty': [len(male[male['Counter_full_pred_class'] == 'successful'])/n_male,\n",
    "                                 len(male[male['Counter_unaware_pred_class'] == 'successful'])/n_male,\n",
    "                                 len(male[male['Counter_fair_pred_class'] == 'successful'])/n_male]\n",
    "}, index = ['Full Model', 'Unaware Model', 'Fair Model(learned)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a902a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
