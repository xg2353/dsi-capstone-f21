{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1036e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('law_data.csv')\n",
    "\n",
    "#Preprocessing\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df = df[df['region_first'] != 'PO']\n",
    "\n",
    "#Hot code race\n",
    "race_coded = pd.get_dummies(df['race'])\n",
    "df = pd.concat([df, race_coded],axis=1)\n",
    "\n",
    "#Hot code gender\n",
    "gender_coded = pd.get_dummies(df['sex'])\n",
    "gender_coded.columns = ['female', 'male']\n",
    "df = pd.concat([df, gender_coded],axis=1)\n",
    "\n",
    "df = df.drop(columns = ['race', 'sex'])\n",
    "\n",
    "#List of all pretected arrtibutes\n",
    "sense_cols = ['Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican', 'Other','Puertorican', 'White', 'female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8260384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#In our model, ZFYA is something we are interested in, so mark it as y, note that the ZFYA is standardized.\n",
    "X = df.loc[:, df.columns !='ZFYA']\n",
    "y = df['ZFYA']\n",
    "\n",
    "#split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get length of dataset\n",
    "n = len(X_train)\n",
    "ne = len(X_test)\n",
    "\n",
    "K = len(sense_cols)  #latent variable knowledge that affects gpa, last and fya, but is not related to race and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f127243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast to int to make computation easier\n",
    "X_train['LSAT'] = X_train['LSAT'].astype(int)\n",
    "X_test['LSAT'] = X_test['LSAT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f8477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part defines data we use in STAN package\n",
    "law_stan_data = {\n",
    "    'N' : n, #number of observations\n",
    "    'K' : K, #number of attributes\n",
    "    'a' : np.array(X_train[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_train['UGPA']), #gpa data \n",
    "    'lsat' : np.array(X_train['LSAT']), #sat data\n",
    "    'zfya' : np.array(y_train) #zfya data\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34ca58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part defines a model for STAN package to use, the model basically defines all distribution in paper page 8.\n",
    "#\n",
    "\n",
    "model= \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  real           zfya[N]; // ZFYA\n",
    "  \n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  \n",
    " vector[K] zero_K;\n",
    " vector[K] one_K;\n",
    " \n",
    " zero_K = rep_vector(0,K);\n",
    " one_K = rep_vector(1,K);\n",
    "\n",
    "}\n",
    "\n",
    "parameters {\n",
    "\n",
    "  //this stands for knowledge, the pretected attribute\n",
    "  vector[N] u; \n",
    "\n",
    "  real ugpa0;\n",
    "  real eta_u_ugpa;\n",
    "  real lsat0;\n",
    "  real eta_u_lsat;\n",
    "  real eta_u_zfya;\n",
    "  \n",
    "  vector[K] eta_a_ugpa;\n",
    "  vector[K] eta_a_lsat;\n",
    "  vector[K] eta_a_zfya;\n",
    "  \n",
    "  \n",
    "  real<lower=0> sigma_g_Sq;\n",
    "}\n",
    "\n",
    "transformed parameters  {\n",
    " // Population standard deviation (a positive real number)\n",
    " real<lower=0> sigma_g;\n",
    " // Standard deviation (derived from variance)\n",
    " sigma_g = sqrt(sigma_g_Sq);\n",
    "}\n",
    "\n",
    "model {\n",
    "  \n",
    "  // don't have data about this, so we could assume those data are normally distributed\n",
    "  u ~ normal(0, 1);\n",
    "  \n",
    "  ugpa0 ~ normal(0, 1);\n",
    "  eta_u_ugpa ~ normal(0, 1);\n",
    "  lsat0 ~ normal(0, 1);\n",
    "  eta_u_lsat ~ normal(0, 1);\n",
    "  eta_u_zfya ~ normal(0, 1);\n",
    "\n",
    "  eta_a_ugpa ~ normal(zero_K, one_K);\n",
    "  eta_a_lsat ~ normal(zero_K, one_K);\n",
    "  eta_a_zfya ~ normal(zero_K, one_K);\n",
    "\n",
    "  sigma_g_Sq ~ inv_gamma(1, 1);\n",
    "\n",
    "  // have data about these, generally want to learn u using all data we know, or assumed. We then \n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g);\n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat));\n",
    "  zfya ~ normal(eta_u_zfya * u + a * eta_a_zfya, 1);\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d857a85",
   "metadata": {},
   "source": [
    "u -> K\n",
    "a -> Include all sensitive variables sex and race using real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6da009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter eta_a_zfya has no priors.\n",
      "Warning: The parameter eta_a_ugpa has no priors.\n",
      "Warning: The parameter eta_a_lsat has no priors.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.008761 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 87.61 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Using STAN package with the model we defined above, this would gives us the posterior distribution knowledge\n",
    "posterior = stan.build(model, data=law_stan_data, random_seed=1)\n",
    "\n",
    "#We then use the u we learned to generate samples\n",
    "fit = posterior.sample(num_chains= 1, num_samples= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaec74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U_train = fit['u'].mean(axis = 1)\n",
    "pd.DataFrame(U_train).to_csv('U_train.csv')\n",
    "\n",
    "#we trying to get an average of those samples, those are learned using u in trainnig and that would be parameters for test set.\n",
    "ugpa0 = fit['ugpa0'].mean()\n",
    "eta_u_ugpa = fit['eta_u_ugpa'].mean()\n",
    "eta_a_ugpa = fit['eta_a_ugpa'].mean(axis = 1)\n",
    "\n",
    "lsat0 = fit['lsat0'].mean()\n",
    "eta_u_lsat = fit['eta_u_lsat'].mean()\n",
    "eta_a_lsat = fit['eta_a_lsat'].mean(axis = 1)\n",
    "\n",
    "sigma_g = fit['sigma_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0f55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have similar setting for test, in this part, we have datas learned during training. \n",
    "\n",
    "model_u = \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  \n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  \n",
    "  //those are learned from training part\n",
    "  real           ugpa0;\n",
    "  real           eta_u_ugpa;\n",
    "  vector[K]      eta_a_ugpa;\n",
    "  real           lsat0;\n",
    "  real           eta_u_lsat;\n",
    "  vector[K]      eta_a_lsat;\n",
    "  real           sigma_g;\n",
    "  \n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "\n",
    "  vector[N] u;\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  \n",
    "  u ~ normal(0, 1);\n",
    "\n",
    "  // have data about these, we again using data we know to learn u again\n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g); \n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat)); \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7161c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Those are data we learned from training\n",
    "law_stan_test_data = {\n",
    "    'N' : ne, #number of test data\n",
    "    'K' : K, #number of protected attributes\n",
    "    'a' : np.array(X_test[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_test['UGPA']), #ugpa\n",
    "    'lsat' : np.array(X_test['LSAT']), #lsat\n",
    "    \n",
    "    #those are learned from training\n",
    "    'ugpa0' : ugpa0, \n",
    "    'eta_u_ugpa' : eta_u_ugpa,\n",
    "    'eta_a_ugpa' : eta_a_ugpa,\n",
    "    'lsat0' : lsat0, \n",
    "    'eta_u_lsat' : eta_u_lsat,\n",
    "    'eta_a_lsat' : eta_a_lsat,\n",
    "    'sigma_g' : sigma_g    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f07addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.001374 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 13.74 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "#again learn posterior from model above\n",
    "posterior_test = stan.build(model_u, data=law_stan_test_data, random_seed=1)\n",
    "\n",
    "#generate samples \n",
    "fit_test = posterior_test.sample(num_chains= 1, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96dc26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This would be the knowledge we learned from testing by taking average of all samples\n",
    "U_test = fit_test['u'].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63b971",
   "metadata": {},
   "source": [
    "# Fair Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c484a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fair + non-deterministic model (deterministic)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#We get those data using U we learned above\n",
    "X_fair = U_train.reshape(-1,1)\n",
    "X_fair_test = U_test.reshape(-1, 1)\n",
    "\n",
    "lr_fair = LinearRegression()\n",
    "lr_fair.fit(X_fair, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b6835",
   "metadata": {},
   "source": [
    "# Unfair models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17fa62d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A. Full model\n",
    "full_list = ['LSAT', 'UGPA', 'Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican','Other', 'Puertorican', 'White', 'female', 'male']\n",
    "lr_full = LinearRegression()\n",
    "lr_full.fit(X_train[full_list], y_train)\n",
    "\n",
    "#B. Unaware model\n",
    "unaware = ['LSAT', 'UGPA']\n",
    "lr_unaware = LinearRegression()\n",
    "lr_unaware.fit(X_train[unaware], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9b3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile to one dataset\n",
    "X_train['ZFYA'] = y_train\n",
    "X_train['Knowledge'] = U_train\n",
    "\n",
    "#make ZFYA data binary variable with threshole 0, since it is already standardized\n",
    "X_train['Init_class'] = np.sign(X_train['ZFYA'])\n",
    "\n",
    "#fair model\n",
    "X_train['Fair_pred'] = lr_fair.predict(X_fair)\n",
    "X_train['Fair_pred_class'] = np.sign(X_train['Fair_pred'])\n",
    "\n",
    "#full model\n",
    "X_train['full_pred'] = lr_full.predict(X_train[full_list])\n",
    "X_train['full_pred_class'] = np.sign(X_train['full_pred'])\n",
    "\n",
    "#unaware model\n",
    "X_train['unaware_pred'] = lr_unaware.predict(X_train[unaware])\n",
    "X_train['unaware_pred_class'] = np.sign(X_train['unaware_pred'])\n",
    "\n",
    "X_train.to_csv('Full_Training_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e753bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar here for test set\n",
    "X_test['ZFYA'] = y_test\n",
    "X_test['Knowledge'] = U_test\n",
    "\n",
    "X_test['Init_class'] = np.sign(X_test['ZFYA'])\n",
    "\n",
    "X_test['Fair_pred'] = lr_fair.predict(X_fair_test)\n",
    "X_test['Fair_pred_class'] = np.sign(X_test['Fair_pred'])\n",
    "\n",
    "X_test['full_pred'] = lr_full.predict(X_test[full_list])\n",
    "X_test['full_pred_class'] = np.sign(X_test['full_pred'])\n",
    "\n",
    "X_test['unaware_pred'] = lr_unaware.predict(X_test[unaware])\n",
    "X_test['unaware_pred_class'] = np.sign(X_test['unaware_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e3482ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('Full_Test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e982171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LSAT', 'UGPA', 'region_first', 'sander_index', 'first_pf',\n",
       "       'Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican', 'Other',\n",
       "       'Puertorican', 'White', 'female', 'male', 'ZFYA', 'Knowledge',\n",
       "       'Init_class', 'Fair_pred', 'Fair_pred_class', 'full_pred',\n",
       "       'full_pred_class', 'unaware_pred', 'unaware_pred_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645c8ee",
   "metadata": {},
   "source": [
    "# Counterfactual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de0eeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender counterfactual\n",
    "male_counter = X_test['female']\n",
    "female_counter = X_test['male']\n",
    "\n",
    "test_counter = X_test.copy()\n",
    "test_counter['male'] = male_counter\n",
    "test_counter['female'] = female_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05c8d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get everything and male\n",
    "test_counter = test_counter.loc[:, 'LSAT':'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bf98011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.00178 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 17.8 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar steps here for stan \n",
    "law_stan_counter_data = {\n",
    "    'N' : ne,\n",
    "    'K' : K,\n",
    "    'a' : np.array(test_counter[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(test_counter['UGPA']), \n",
    "    'lsat' : np.array(test_counter['LSAT']),\n",
    "    'ugpa0' : ugpa0,\n",
    "    'eta_u_ugpa' : eta_u_ugpa,\n",
    "    'eta_a_ugpa' : eta_a_ugpa,\n",
    "    'lsat0' : lsat0, \n",
    "    'eta_u_lsat' : eta_u_lsat,\n",
    "    'eta_a_lsat' : eta_a_lsat,\n",
    "    'sigma_g' : sigma_g    \n",
    "}\n",
    "\n",
    "counter_post = stan.build(model_u, data=law_stan_counter_data, random_seed=1)\n",
    "counter_fit = counter_post.sample(num_chains= 1, num_samples=50)\n",
    "counter_U = counter_fit['u'].mean(axis = 1)\n",
    "counter_fair_K = counter_U.reshape(-1, 1)\n",
    "\n",
    "counter_fair = LinearRegression()\n",
    "counter_fair.fit(counter_fair_K, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "088026da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter['ZFYA'] = y_test\n",
    "test_counter['Knowledge'] = counter_fair_K\n",
    "\n",
    "test_counter['Init_class'] = np.sign(X_test['ZFYA'])\n",
    "\n",
    "test_counter['Fair_pred'] = counter_fair.predict(counter_fair_K)\n",
    "test_counter['Fair_pred_class'] = np.sign(test_counter['Fair_pred'])\n",
    "\n",
    "test_counter['full_pred'] = lr_full.predict(test_counter[full_list])\n",
    "test_counter['full_pred_class'] = np.sign(test_counter['full_pred'])\n",
    "\n",
    "test_counter['unaware_pred'] = lr_unaware.predict(test_counter[unaware])\n",
    "test_counter['unaware_pred_class'] = np.sign(test_counter['unaware_pred'])\n",
    "\n",
    "test_counter.to_csv('Counter_Test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ca353",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0ecf602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Full_test_df.csv')\n",
    "df2 = pd.read_csv('Counter_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "befa204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {-1: 'unsuccessful', 1: 'successful'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cc02e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'Gender': df1['female'].map({0: 'male', 1:'female'}),\n",
    "    'Init_class': df1['Init_class'].map(mapping),\n",
    "    \n",
    "    'Fair_pred_class': df1['Fair_pred_class'].map(mapping),\n",
    "    'Counter_fair_pred_class': df2['Fair_pred_class'].map(mapping),\n",
    "    \n",
    "    'full_pred_class':df1['full_pred_class'].map(mapping),\n",
    "    'Counter_full_pred_class': df2['full_pred_class'].map(mapping),\n",
    "    \n",
    "    'unaware_pred_class':df1['unaware_pred_class'].map(mapping),\n",
    "    'Counter_unaware_pred_class': df2['unaware_pred_class'].map(mapping)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e9b675a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Init_class</th>\n",
       "      <th>Fair_pred_class</th>\n",
       "      <th>Counter_fair_pred_class</th>\n",
       "      <th>full_pred_class</th>\n",
       "      <th>Counter_full_pred_class</th>\n",
       "      <th>unaware_pred_class</th>\n",
       "      <th>Counter_unaware_pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>unsuccessful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>successful</td>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Init_class Fair_pred_class Counter_fair_pred_class full_pred_class  \\\n",
       "0    male  successful      successful              successful    unsuccessful   \n",
       "1  female  successful    unsuccessful              successful      successful   \n",
       "2  female  successful      successful              successful      successful   \n",
       "3    male  successful      successful              successful      successful   \n",
       "4  female  successful      successful              successful      successful   \n",
       "\n",
       "  Counter_full_pred_class unaware_pred_class Counter_unaware_pred_class  \n",
       "0            unsuccessful       unsuccessful               unsuccessful  \n",
       "1              successful         successful                 successful  \n",
       "2              successful         successful                 successful  \n",
       "3              successful         successful                 successful  \n",
       "4              successful         successful                 successful  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd8f6f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32c0fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observation = len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6fb02f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3824"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result['Fair_pred_class'] == result['Counter_fair_pred_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34ffed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = result[result['Gender'] == 'female']\n",
    "male = result[result['Gender'] == 'male']   \n",
    "n_female = len(female)\n",
    "n_male = len(male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33dafb",
   "metadata": {},
   "source": [
    "# Female: Predicted probability to succeed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db6a9828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proability</th>\n",
       "      <th>Counterfactual Probabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Model</th>\n",
       "      <td>0.718220</td>\n",
       "      <td>0.748941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unaware Model</th>\n",
       "      <td>0.661547</td>\n",
       "      <td>0.661547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair Model(learned)</th>\n",
       "      <td>0.736758</td>\n",
       "      <td>0.934322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Proability  Counterfactual Probabilty\n",
       "Full Model             0.718220                   0.748941\n",
       "Unaware Model          0.661547                   0.661547\n",
       "Fair Model(learned)    0.736758                   0.934322"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Proability': [len(female[female['full_pred_class'] == 'successful'])/n_female, \n",
    "                   len(female[female['unaware_pred_class'] == 'successful'])/n_female,\n",
    "                   len(female[female['Fair_pred_class'] == 'successful'])/n_female\n",
    "                  ],\n",
    "    'Counterfactual Probabilty': [len(female[female['Counter_full_pred_class'] == 'successful'])/n_female,\n",
    "                                 len(female[female['Counter_unaware_pred_class'] == 'successful'])/n_female,\n",
    "                                 len(female[female['Counter_fair_pred_class'] == 'successful'])/n_female]\n",
    "}, index = ['Full Model', 'Unaware Model', 'Fair Model(learned)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e256d2",
   "metadata": {},
   "source": [
    "# Male: Predicted probability to succeed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bcf03f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proability</th>\n",
       "      <th>Counterfactual Probabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Model</th>\n",
       "      <td>0.759109</td>\n",
       "      <td>0.724291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unaware Model</th>\n",
       "      <td>0.650607</td>\n",
       "      <td>0.650607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair Model(learned)</th>\n",
       "      <td>0.729960</td>\n",
       "      <td>0.794332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Proability  Counterfactual Probabilty\n",
       "Full Model             0.759109                   0.724291\n",
       "Unaware Model          0.650607                   0.650607\n",
       "Fair Model(learned)    0.729960                   0.794332"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Proability': [len(male[male['full_pred_class'] == 'successful'])/n_male, \n",
    "                   len(male[male['unaware_pred_class'] == 'successful'])/n_male,\n",
    "                   len(male[male['Fair_pred_class'] == 'successful'])/n_male\n",
    "                  ],\n",
    "    'Counterfactual Probabilty': [len(male[male['Counter_full_pred_class'] == 'successful'])/n_male,\n",
    "                                 len(male[male['Counter_unaware_pred_class'] == 'successful'])/n_male,\n",
    "                                 len(male[male['Counter_fair_pred_class'] == 'successful'])/n_male]\n",
    "}, index = ['Full Model', 'Unaware Model', 'Fair Model(learned)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
