{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1036e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('law_data.csv')\n",
    "\n",
    "#Preprocessing\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df = df[df['region_first'] != 'PO']\n",
    "\n",
    "#Code race\n",
    "race_coded = pd.get_dummies(df['race'])\n",
    "df = pd.concat([df, race_coded],axis=1)\n",
    "\n",
    "#Code gender\n",
    "gender_coded = pd.get_dummies(df['sex'])\n",
    "gender_coded.columns = ['female', 'male']\n",
    "df = pd.concat([df, gender_coded],axis=1)\n",
    "\n",
    "df = df.drop(columns = ['race', 'sex'])\n",
    "sense_cols = ['Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican', 'Other','Puertorican', 'White', 'female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8260384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, df.columns !='ZFYA']\n",
    "y = df['ZFYA']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "ne = len(X_test)\n",
    "K = len(sense_cols)  #latent variable knowledge that affects gpa, last and fya, but is not related to race and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f127243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['LSAT'] = X_train['LSAT'].astype(int)\n",
    "X_test['LSAT'] = X_test['LSAT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f8477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_stan_data = {\n",
    "    'N' : n, #number of observations\n",
    "    'K' : K, \n",
    "    'a' : np.array(X_train[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_train['UGPA']), \n",
    "    'lsat' : np.array(X_train['LSAT']),\n",
    "    'zfya' : np.array(y_train)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34ca58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  real           zfya[N]; // ZFYA\n",
    "  \n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  \n",
    " vector[K] zero_K;\n",
    " vector[K] one_K;\n",
    " \n",
    " zero_K = rep_vector(0,K);\n",
    " one_K = rep_vector(1,K);\n",
    "\n",
    "}\n",
    "\n",
    "parameters {\n",
    "\n",
    "  vector[N] u;\n",
    "\n",
    "  real ugpa0;\n",
    "  real eta_u_ugpa;\n",
    "  real lsat0;\n",
    "  real eta_u_lsat;\n",
    "  real eta_u_zfya;\n",
    "  \n",
    "  vector[K] eta_a_ugpa;\n",
    "  vector[K] eta_a_lsat;\n",
    "  vector[K] eta_a_zfya;\n",
    "  \n",
    "  \n",
    "  real<lower=0> sigma_g_Sq;\n",
    "}\n",
    "\n",
    "transformed parameters  {\n",
    " // Population standard deviation (a positive real number)\n",
    " real<lower=0> sigma_g;\n",
    " // Standard deviation (derived from variance)\n",
    " sigma_g = sqrt(sigma_g_Sq);\n",
    "}\n",
    "\n",
    "model {\n",
    "  \n",
    "  // don't have data about this\n",
    "  u ~ normal(0, 1);\n",
    "  \n",
    "  ugpa0 ~ normal(0, 1);\n",
    "  eta_u_ugpa ~ normal(0, 1);\n",
    "  lsat0 ~ normal(0, 1);\n",
    "  eta_u_lsat ~ normal(0, 1);\n",
    "  eta_u_zfya ~ normal(0, 1);\n",
    "\n",
    "  eta_a_ugpa ~ normal(zero_K, one_K);\n",
    "  eta_a_lsat ~ normal(zero_K, one_K);\n",
    "  eta_a_zfya ~ normal(zero_K, one_K);\n",
    "\n",
    "  sigma_g_Sq ~ inv_gamma(1, 1);\n",
    "\n",
    "  // have data about these\n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g);\n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat));\n",
    "  zfya ~ normal(eta_u_zfya * u + a * eta_a_zfya, 1);\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef382beb",
   "metadata": {},
   "source": [
    "u -> K\n",
    "a -> Include all sensitive variables sex and race using real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6da009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter eta_a_zfya has no priors.\n",
      "Warning: The parameter eta_a_ugpa has no priors.\n",
      "Warning: The parameter eta_a_lsat has no priors.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.008761 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 87.61 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "posterior = stan.build(model, data=law_stan_data, random_seed=1)\n",
    "fit = posterior.sample(num_chains= 1, num_samples= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaec74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_train = fit['u'].mean(axis = 1)\n",
    "pd.DataFrame(U_train).to_csv('U_train.csv')\n",
    "\n",
    "ugpa0 = fit['ugpa0'].mean()\n",
    "eta_u_ugpa = fit['eta_u_ugpa'].mean()\n",
    "eta_a_ugpa = fit['eta_a_ugpa'].mean(axis = 1)\n",
    "\n",
    "lsat0 = fit['lsat0'].mean()\n",
    "eta_u_lsat = fit['eta_u_lsat'].mean()\n",
    "eta_a_lsat = fit['eta_a_lsat'].mean(axis = 1)\n",
    "\n",
    "sigma_g = fit['sigma_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2ca21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_u = \"\"\"\n",
    "data {\n",
    "  int<lower = 0> N; // number of observations\n",
    "  int<lower = 0> K; // number of covariates\n",
    "  \n",
    "  matrix[N, K]   a; // sensitive variables\n",
    "  real           ugpa[N]; // UGPA\n",
    "  int            lsat[N]; // LSAT\n",
    "  //real           zfya[N]; // ZFYA\n",
    "  //int<lower = 0> pass[N]; // PASS\n",
    "  real           ugpa0;\n",
    "  real           eta_u_ugpa;\n",
    "  vector[K]      eta_a_ugpa;\n",
    "  real           lsat0;\n",
    "  real           eta_u_lsat;\n",
    "  vector[K]      eta_a_lsat;\n",
    "  //real           eta_u_zfya;\n",
    "  //vector[K]      eta_a_zfya;\n",
    "  //real           pass0;\n",
    "  //real           eta_u_pass;\n",
    "  //vector[K]      eta_a_pass;\n",
    "  real           sigma_g;\n",
    "  \n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "\n",
    "  vector[N] u;\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  \n",
    "  u ~ normal(0, 1);\n",
    "\n",
    "  // have data about these\n",
    "  ugpa ~ normal(ugpa0 + eta_u_ugpa * u + a * eta_a_ugpa, sigma_g); \n",
    "  lsat ~ poisson(exp(lsat0 + eta_u_lsat * u + a * eta_a_lsat)); \n",
    "  //zfya ~ normal(eta_u_zfya * u + a * eta_a_zfya,1);\n",
    "  //pass ~ bernoulli_logit(pass0 + eta_u_pass * u + a * eta_a_pass);\n",
    "  \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3777933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_stan_test_data = {\n",
    "    'N' : ne,\n",
    "    'K' : K,\n",
    "    'a' : np.array(X_test[sense_cols]), #protected variable race and sex\n",
    "    'ugpa' : np.array(X_test['UGPA']), \n",
    "    'lsat' : np.array(X_test['LSAT']),\n",
    "    'ugpa0' : ugpa0,\n",
    "    'eta_u_ugpa' : eta_u_ugpa,\n",
    "    'eta_a_ugpa' : eta_a_ugpa,\n",
    "    'lsat0' : lsat0, \n",
    "    'eta_u_lsat' : eta_u_lsat,\n",
    "    'eta_a_lsat' : eta_a_lsat,\n",
    "    'sigma_g' : sigma_g    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de2cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Sampling:   0%\n",
      "Sampling:   0% (1/1050)\n",
      "Sampling:  10% (100/1050)\n",
      "Sampling:  19% (200/1050)\n",
      "Sampling:  29% (300/1050)\n",
      "Sampling:  38% (400/1050)\n",
      "Sampling:  48% (500/1050)\n",
      "Sampling:  57% (600/1050)\n",
      "Sampling:  67% (700/1050)\n",
      "Sampling:  76% (800/1050)\n",
      "Sampling:  86% (900/1050)\n",
      "Sampling:  95% (1000/1050)\n",
      "Sampling:  95% (1001/1050)\n",
      "Sampling: 100% (1050/1050)\n",
      "Sampling: 100% (1050/1050), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.001374 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 13.74 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "posterior_test = stan.build(model_u, data=law_stan_test_data, random_seed=1)\n",
    "fit_test = posterior_test.sample(num_chains= 1, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd813549",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_test = fit_test['u'].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78c031",
   "metadata": {},
   "source": [
    "# Fair Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bde0b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fair + non-deterministic model (deterministic)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_fair = U_train.reshape(-1,1)\n",
    "X_fair_test = U_test.reshape(-1, 1)\n",
    "\n",
    "lr_fair = LinearRegression()\n",
    "lr_fair.fit(X_fair, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc93aab",
   "metadata": {},
   "source": [
    "# Unfair models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f32f690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A. Full model\n",
    "full_list = ['LSAT', 'UGPA', 'Amerindian', 'Asian', 'Black', 'Hispanic', 'Mexican','Other', 'Puertorican', 'White', 'female', 'male']\n",
    "lr_full = LinearRegression()\n",
    "lr_full.fit(X_train[full_list], y_train)\n",
    "\n",
    "#B. Unaware model\n",
    "unaware = ['LSAT', 'UGPA']\n",
    "lr_unaware = LinearRegression()\n",
    "lr_unaware.fit(X_train[unaware], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86eed1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile to one dataset\n",
    "X_train['ZFYA'] = y_train\n",
    "X_train['Knowledge'] = U_train\n",
    "\n",
    "X_train['Init_class'] = np.sign(X_train['ZFYA'])\n",
    "\n",
    "X_train['Fair_pred'] = lr_fair.predict(X_fair)\n",
    "X_train['Fair_pred_class'] = np.sign(X_train['Fair_pred'])\n",
    "\n",
    "X_train['full_pred'] = lr_full.predict(X_train[full_list])\n",
    "X_train['full_pred_class'] = np.sign(X_train['full_pred'])\n",
    "\n",
    "X_train['unaware_pred'] = lr_unaware.predict(X_train[unaware])\n",
    "X_train['unaware_pred_class'] = np.sign(X_train['unaware_pred'])\n",
    "\n",
    "X_train.to_csv('Full_Training_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0291bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['ZFYA'] = y_test\n",
    "X_test['Knowledge'] = U_test\n",
    "\n",
    "X_test['Init_class'] = np.sign(X_test['ZFYA'])\n",
    "\n",
    "X_test['Fair_pred'] = lr_fair.predict(X_fair_test)\n",
    "X_test['Fair_pred_class'] = np.sign(X_test['Fair_pred'])\n",
    "\n",
    "X_test['full_pred'] = lr_full.predict(X_test[full_list])\n",
    "X_test['full_pred_class'] = np.sign(X_test['full_pred'])\n",
    "\n",
    "X_test['unaware_pred'] = lr_unaware.predict(X_test[unaware])\n",
    "X_test['unaware_pred_class'] = np.sign(X_test['unaware_pred'])\n",
    "\n",
    "X_test.to_csv('Full_Test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d79943",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940ccc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
